{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa4e445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(init='random', max_iter=300, n_clusters=8000, n_init=10,\n",
       "                random_state=42)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as infile:\n",
    "        matrix = cPickle.load(infile)    \n",
    "    return matrix\n",
    "\n",
    "data = pd.read_pickle(\"/home/amir/Desktop/CAE/descriptor_128.csv\")\n",
    "from os.path import isfile, join\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "principalComponents = pca.fit_transform(np.asmatrix(data))\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "dictionary =  MiniBatchKMeans(init=\"random\",n_clusters=8000,  n_init=10,  max_iter=300, random_state=42)\n",
    "dictionary.fit(np.array(principalComponents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bea94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary.labels_)\n",
    "import numpy as np\n",
    "def normalize_row(row):\n",
    "    for i in range(0,len(row)):\n",
    "        row[i]=(row[i]-np.min(row))/(np.max(row)-np.min(row))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b0791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227904"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "len(dictionary.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b926c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,data.shape[0]):\n",
    "    data[i,:]=normalize_row(data[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b95b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_1_Y = dictionary.labels_[0:113952]\n",
    "part_2_Y = dictionary.labels_[113952:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c1adb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_1_X = data[0:113952,:]\n",
    "part_2_X = data[113952:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6943520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d782ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_part_1, X_test_part_1, y_train_part_1, y_test_part_1 = train_test_split(part_1_X, part_1_Y, test_size=0.33)\n",
    "X_train_part_2, X_test_part_2, y_train_part_2, y_test_part_2 = train_test_split(part_2_X , part_2_Y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "ax= csr_matrix(np.arange(40000000000).reshape((200000,200000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6308a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             X:  1.9 TiB\n",
      "                          data: 55.6 MiB\n",
      "          encoded_train_part_1: 18.6 MiB\n",
      "          encoded_train_part_2: 18.6 MiB\n",
      "                            NN: 10.0 MiB\n",
      "                           _75: 10.0 MiB\n",
      "           encoded_test_part_1:  9.2 MiB\n",
      "           encoded_test_part_2:  9.2 MiB\n",
      "                y_train_part_1: 298.3 KiB\n",
      "                y_train_part_2: 298.3 KiB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "53bde030",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_k =99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d7b66774",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(dictionary.labels_), len(dictionary.labels_)*40), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2473a599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227904"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0152fd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227904"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c49805a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = data.reshape(data.shape[0],128)\n",
    "X_train_part_1 = X_train_part_1.reshape(-1, 128, 1)\n",
    "X_train_part_2 = X_train_part_2.reshape(-1, 128, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], 128)\n",
    "\n",
    "#############################################################\n",
    "#############################################################\n",
    "\n",
    "X_test_part_1 = X_test_part_1.reshape(-1, 128, 1)\n",
    "X_test_part_2 = X_test_part_2.reshape(-1, 128, 1)\n",
    "\n",
    "#############################################################\n",
    "#############################################################\n",
    "X_train_part_2=X_train_part_2[:,:,np.newaxis]\n",
    "X_train_part_1=X_train_part_1[:,:,np.newaxis]\n",
    "\n",
    "X_test_part_2=X_test_part_2[:,:,np.newaxis]\n",
    "X_test_part_1=X_test_part_1[:,:,np.newaxis]\n",
    "#############################################################\n",
    "#############################################################\n",
    "\n",
    "X_test_part_2 = np.squeeze(X_test_part_2,axis=3)\n",
    "X_test_part_1 = np.squeeze(X_test_part_1,axis=3)\n",
    "#############################################################\n",
    "#############################################################\n",
    "\n",
    "X_train_part_1 = np.squeeze(X_train_part_1,axis=3)\n",
    "X_train_part_2 = np.squeeze(X_train_part_2,axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21ea8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 1024\n",
    "num_classes = 8000\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Input,Dense,Flatten,Dropout,Reshape,Conv1D,MaxPooling1D,UpSampling1D,AveragePooling1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#batch_size = 64\n",
    "epochs = 1\n",
    "inChannel = 1\n",
    "x, y = 128, 1\n",
    "input_img = Input(shape = (x, y))\n",
    "\n",
    "num_classes = 8000\n",
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv1D(32 ,3, activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv1D(32,3, activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv1D(64, 3, activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv1D(64, 3, activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv1D(128,  3, activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv1D(128, 3, activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv1D(256 ,3, activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv1D(256,3 , activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4\n",
    "\n",
    "def decoder(conv4):    \n",
    "    #decoder\n",
    "    conv5 = Conv1D(128, 3, activation='relu', padding='same')(conv4) #7 x 7 x 128\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv1D(128, 3, activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv6 = Conv1D(64, 3, activation='relu', padding='same')(conv5) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv1D(64, 3, activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling1D((2))(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv1D(32, 3, activation='relu', padding='same')(up1) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv1D(32, 3, activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling1D(2)(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv1D(1, 3, activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded\n",
    "\n",
    "autoencoder_1 = Model(input_img, decoder(encoder(input_img)))\n",
    "autoencoder_1.compile(loss='mse', optimizer = Adam())\n",
    "autoencoder_2 = Model(input_img, decoder(encoder(input_img)))\n",
    "autoencoder_2.compile(loss='mse', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa66eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "597/597 [==============================] - 136s 221ms/step - loss: 0.0286\n",
      "Epoch 2/5\n",
      "597/597 [==============================] - 136s 228ms/step - loss: 0.0023\n",
      "Epoch 3/5\n",
      "597/597 [==============================] - 135s 227ms/step - loss: 0.0011\n",
      "Epoch 4/5\n",
      "597/597 [==============================] - 136s 227ms/step - loss: 7.9728e-04\n",
      "Epoch 5/5\n",
      "597/597 [==============================] - 134s 225ms/step - loss: 5.9655e-04\n",
      "Epoch 1/5\n",
      "597/597 [==============================] - 141s 228ms/step - loss: 0.0222\n",
      "Epoch 2/5\n",
      "597/597 [==============================] - 131s 220ms/step - loss: 0.0019\n",
      "Epoch 3/5\n",
      "597/597 [==============================] - 136s 227ms/step - loss: 0.0012\n",
      "Epoch 4/5\n",
      "597/597 [==============================] - 136s 227ms/step - loss: 8.3488e-04\n",
      "Epoch 5/5\n",
      "597/597 [==============================] - 134s 224ms/step - loss: 6.1074e-04\n"
     ]
    }
   ],
   "source": [
    "classify_train_1 = autoencoder_1.fit(X_train_part_1, X_train_part_1, batch_size=128,epochs=5)\n",
    "classify_train_2 = autoencoder_2.fit(X_train_part_2, X_train_part_2, batch_size=128,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9361c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv1D(32 ,3, activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv1D(32,3, activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv1D(64, 3, activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv1D(64, 3, activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv1D(128,  3, activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv1D(128, 3, activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv1D(256 ,3, activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv1D(256,3 , activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4\n",
    "\n",
    "def fc(enco,data):\n",
    "    flat = Flatten()(enco)\n",
    "    n_bottleneck = round(float(data)/2.0)\n",
    "    bottleneck = Dense(n_bottleneck, activation='relu')(flat)\n",
    "    #den = Dense(128, activation='relu')(flat)\n",
    "    #out = Dense(num_classes, activation='softmax')(den)\n",
    "    return bottleneck\n",
    "\n",
    "#bottleneck = Dense(n_bottleneck)(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9db5c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = encoder(input_img)\n",
    "full_model_1 = Model(input_img,fc(encode,X_train_part_1.shape[1]))\n",
    "full_model_1.compile(loss='mse', optimizer = Adam())\n",
    "\n",
    "#####################\n",
    "full_model_2 = Model(input_img,fc(encode,X_train_part_2.shape[1]))\n",
    "full_model_2.compile(loss='mse', optimizer = Adam())\n",
    "\n",
    "for layer in full_model_1.layers[0:19]:\n",
    "    layer.trainable = True\n",
    "for l1,l2 in zip(full_model_1.layers[:19],autoencoder_1.layers[0:19]):\n",
    "    l1.set_weights(l2.get_weights())  \n",
    "    \n",
    "for layer in full_model_2.layers[0:19]:\n",
    "    layer.trainable = True\n",
    "for l1,l2 in zip(full_model_2.layers[:19],autoencoder_2.layers[0:19]):\n",
    "    l1.set_weights(l2.get_weights())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b5b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "797ae59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_part_1 = full_model_1.predict(X_train_part_1)\n",
    "encoded_test_part_1 = full_model_1.predict(X_test_part_1)\n",
    "encoded_train_part_2 = full_model_2.predict(X_train_part_2)\n",
    "encoded_test_part_2 = full_model_2.predict(X_test_part_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3bd712b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76347, 64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_part_1[0:76347,:]\n",
    "[76347:113952,:]\n",
    "encoded_train_part_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f92594cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227904"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_part_1.shape[0]+encoded_test_part_1.shape[0]+encoded_test_part_2.shape[0]+encoded_train_part_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e240a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_part_1 = np.float32(encoded_train_part_1)\n",
    "encoded_test_part_1 = np.float32(encoded_test_part_1)\n",
    "encoded_train_part_2 = np.float32(encoded_train_part_2)\n",
    "encoded_test_part_2 = np.float32(encoded_test_part_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba970c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((227904,64),dtype=\"float32\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f88cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((227904,64),dtype=\"float32\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c607349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:encoded_train_part_1.shape[0],:]=encoded_train_part_1\n",
    "data[encoded_train_part_1.shape[0]:encoded_test_part_1.shape[0]+encoded_train_part_1.shape[0],:] = encoded_test_part_1\n",
    "data[encoded_test_part_1.shape[0]+encoded_train_part_1.shape[0]:encoded_test_part_1.shape[0]+encoded_train_part_1.shape[0]+encoded_train_part_2.shape[0],:] = encoded_train_part_2\n",
    "data[encoded_test_part_1.shape[0]+encoded_train_part_1.shape[0]+encoded_train_part_2.shape[0]:,:] = encoded_test_part_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e4c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle as cPickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as infile:\n",
    "        matrix = cPickle.load(infile)    \n",
    "    return matrix\n",
    "\n",
    "def save_pickle(matrix, filename):\n",
    "    with open(filename, 'wb') as outfile:\n",
    "        cPickle.dump(matrix, outfile, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a6dc0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c982a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023f871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1b8b664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([227903, 127469, 188644, 197563, 217368, 163161, 120760, 185090,\n",
       "       194635, 163621, 194385, 209841, 212894, 119492, 182511, 136923,\n",
       "       210490, 216446, 120041, 168916, 202656, 120918, 154877, 119704,\n",
       "       162784, 190559, 120311, 169541, 200655, 202332, 128005, 119784,\n",
       "       167958, 215567, 201112, 217414, 147584, 157436, 177875, 129196,\n",
       "       159057, 182337, 193154, 119076, 218166, 131560, 209952, 192742,\n",
       "       194091, 197978, 138725, 149287, 216238, 154507, 209468, 162217,\n",
       "       201615, 162817, 137735, 171564, 117828, 221058, 207605, 216753,\n",
       "       223120, 199985, 186170, 159171, 115010, 124846, 168408, 133221,\n",
       "       164715, 122924, 146077, 209114, 148471, 192336, 217480, 211971,\n",
       "       174386, 152241, 218119, 213332, 208312, 163117, 226992, 211518,\n",
       "       134609, 227748, 181515, 156244, 121058, 137670, 133795, 148467,\n",
       "       129808, 172215, 132408, 201406, 153367, 227607, 201796, 175060,\n",
       "       182146, 126313, 221935, 122221, 227253, 126609, 134363, 221126,\n",
       "       157007, 184080, 209721, 136793, 114522, 214290, 190812, 129214,\n",
       "       222376, 219365, 195020, 201248, 118909, 125756, 121488, 194439,\n",
       "       142239, 186570, 146814, 182001, 139072, 137194, 153720, 177880,\n",
       "       170639, 224828, 163061, 129087, 192783, 151583, 200095, 181422,\n",
       "       123686, 201974, 124951, 167005, 151560, 159695, 142160, 154848,\n",
       "       125261, 222838, 136310, 189971, 226871, 201646, 132919, 144266,\n",
       "       213000, 152111, 201196, 116505, 150455, 172904, 144330, 165856,\n",
       "       123063, 116268, 171919, 153482, 209414, 170788, 132039, 227219,\n",
       "       164570, 137728, 163863, 150929, 172548, 143080, 125027, 202884,\n",
       "       143227, 225376, 120830, 134791, 174675, 142111, 133636, 142475,\n",
       "       215158, 178433, 167620, 205995, 160573, 225620, 118777, 215757])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN[227903]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49822490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8581d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(data[0:113952,:],\"/home/amir/Desktop/Nearest_neighbour/part_1_prediction.csv\")\n",
    "save_pickle(data[113952:,:],\"/home/amir/Desktop/Nearest_neighbour/part_2_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5452724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91b5107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(9, 6)\n",
    "B = np.linalg.pinv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "787e7cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 6)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b6d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78087a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(data,\"/home/amir/Desktop/Nearest_neighbour/nearest_neighbor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(data,\"/home/amir/Desktop/Nearest_neighbour/nearest_neighbor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fba3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as infile:\n",
    "        matrix = cPickle.load(infile)    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09a80d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_1 = full_model.evaluate(X_train_part_1,y_train_part_1, verbose=0)\n",
    "#train_eval_2 = full_model.evaluate(train_X_partition_2, test_Y_one_hot, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20b4ca34",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-59a801a3143e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_eval_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_eval_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da85310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN=load_pickle(\"/home/amir/Desktop/CAE/ind.data200.graph\")\n",
    "N_1=load_pickle(\"/home/amir/Desktop/CAE/part_1_prediction.csv\")\n",
    "N_2=load_pickle(\"/home/amir/Desktop/CAE/part_2_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19777c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f042840bcdae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_coordinate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_coordinate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_coordinate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_coordinate\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f042840bcdae>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_coordinate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_coordinate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_coordinate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_coordinate\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_coordinate = [x for x in range(0,len(dictionary.labels_)*200)]\n",
    "y_coordinate = [y for y in range(0,len(dictionary.labels_))]\n",
    "tuples = [(x,y) for x in x_coordinate for y in y_coordinate ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a3499cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coordinate = [y for y in range(0,len(dictionary.labels_))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [(x,y) for x in x_coordinate for y in y_coordinate ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61b0572f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ee4d52f6745c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuples' is not defined"
     ]
    }
   ],
   "source": [
    "r = [x for (x, y) in tuples] \n",
    "c = [y for (x, y) in tuples]\n",
    "data = [1] * len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de8f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789ee8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model.layers[:19],autoencoder.layers[0:19]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[0:19]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = encoder(input_img)\n",
    "full_model = Model(input_img,fc(encode))\n",
    "\n",
    "train_eval_1 = full_model.evaluate(X_train_part_1, y_train_part_1, verbose=0)\n",
    "#train_eval_2 = full_model.evaluate(train_X_partition_2, test_Y_one_hot, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6521b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76347, 128, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_part_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35933460",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_1 = full_model.predict(train_X_partition_1)\n",
    "predicted_train_2 = full_model.predict(train_X_partition_2)\n",
    "\n",
    "predicted_classes_train_1 = np.argmax(np.round(predicted_train_1),axis=1)\n",
    "predicted_classes_train_2 = np.argmax(np.round(predicted_train_2),axis=1)\n",
    "\n",
    "predicted_test_1 = full_model.predict(train_X_partition_1)\n",
    "predicted_classes_test_1 = np.argmax(np.round(predicted_test_1),axis=1)\n",
    "\n",
    "\n",
    "predicted_test_2 = full_model.predict(train_X_partition_2)\n",
    "predicted_classes_test = np.argmax(np.round(predicted_test_2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save_weights('C:/Users/amir/Desktop/TFIDF2/stlucia/train/pca/classification_complete_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2374881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_one_hot = to_categorical(train_labels)\n",
    "test_Y_one_hot = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dcb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[0:19]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de642f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_train = full_model.fit(train_X, train_label, batch_size=64,epochs=100,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
